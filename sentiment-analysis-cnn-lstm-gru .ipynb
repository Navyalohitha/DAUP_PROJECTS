{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":800230,"sourceType":"datasetVersion","datasetId":1305}],"dockerImageVersionId":30918,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-input":true,"_kg_hide-output":true,"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:27:54.270182Z","iopub.execute_input":"2025-04-19T06:27:54.270514Z","iopub.status.idle":"2025-04-19T06:27:54.583527Z","shell.execute_reply.started":"2025-04-19T06:27:54.270486Z","shell.execute_reply":"2025-04-19T06:27:54.582737Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/amazonreviews/test.ft.txt.bz2\n/kaggle/input/amazonreviews/train.ft.txt.bz2\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_columns', 50)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:27:55.024837Z","iopub.execute_input":"2025-04-19T06:27:55.025255Z","iopub.status.idle":"2025-04-19T06:27:55.029200Z","shell.execute_reply.started":"2025-04-19T06:27:55.025231Z","shell.execute_reply":"2025-04-19T06:27:55.028233Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"import bz2\n\ndef decompress_bz2(file_path, output_path):\n    with bz2.open(file_path, 'rt', encoding='utf-8') as file:\n        with open(output_path, 'w', encoding='utf-8') as out_file:\n            out_file.write(file.read())\n\n# Decompress the files\ndecompress_bz2('/kaggle/input/amazonreviews/train.ft.txt.bz2', 'train.ft.txt')\ndecompress_bz2('/kaggle/input/amazonreviews/test.ft.txt.bz2', 'test.ft.txt') ","metadata":{"execution":{"iopub.status.busy":"2025-04-19T06:27:56.195255Z","iopub.execute_input":"2025-04-19T06:27:56.195587Z","iopub.status.idle":"2025-04-19T06:29:34.911647Z","shell.execute_reply.started":"2025-04-19T06:27:56.195562Z","shell.execute_reply":"2025-04-19T06:29:34.910657Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def parse_data(file_path):\n    data = []\n    with open(file_path, 'r', encoding='utf-8') as file:\n        for line in file:\n            label, text = line.split(' ', 1)\n            label = int(label.replace('__label__', ''))\n            data.append((label, text.strip()))\n    return pd.DataFrame(data, columns=['label', 'text'])","metadata":{"execution":{"iopub.status.busy":"2025-04-19T06:29:34.912895Z","iopub.execute_input":"2025-04-19T06:29:34.913289Z","iopub.status.idle":"2025-04-19T06:29:34.923233Z","shell.execute_reply.started":"2025-04-19T06:29:34.913252Z","shell.execute_reply":"2025-04-19T06:29:34.922113Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train = parse_data('train.ft.txt')\ntest = parse_data('test.ft.txt')\n\nprint(\"Train:\")\ntrain","metadata":{"execution":{"iopub.status.busy":"2025-04-19T06:29:34.924684Z","iopub.execute_input":"2025-04-19T06:29:34.924863Z","iopub.status.idle":"2025-04-19T06:29:43.867838Z","shell.execute_reply.started":"2025-04-19T06:29:34.924848Z","shell.execute_reply":"2025-04-19T06:29:43.866995Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Train:\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"         label                                               text\n0            2  Stuning even for the non-gamer: This sound tra...\n1            2  The best soundtrack ever to anything.: I'm rea...\n2            2  Amazing!: This soundtrack is my favorite music...\n3            2  Excellent Soundtrack: I truly like this soundt...\n4            2  Remember, Pull Your Jaw Off The Floor After He...\n...        ...                                                ...\n3599995      1  Don't do it!!: The high chair looks great when...\n3599996      1  Looks nice, low functionality: I have used thi...\n3599997      1  compact, but hard to clean: We have a small ho...\n3599998      1  what is it saying?: not sure what this book is...\n3599999      2  Makes My Blood Run Red-White-And-Blue: I agree...\n\n[3600000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>Stuning even for the non-gamer: This sound tra...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>The best soundtrack ever to anything.: I'm rea...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>Amazing!: This soundtrack is my favorite music...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2</td>\n      <td>Excellent Soundtrack: I truly like this soundt...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2</td>\n      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3599995</th>\n      <td>1</td>\n      <td>Don't do it!!: The high chair looks great when...</td>\n    </tr>\n    <tr>\n      <th>3599996</th>\n      <td>1</td>\n      <td>Looks nice, low functionality: I have used thi...</td>\n    </tr>\n    <tr>\n      <th>3599997</th>\n      <td>1</td>\n      <td>compact, but hard to clean: We have a small ho...</td>\n    </tr>\n    <tr>\n      <th>3599998</th>\n      <td>1</td>\n      <td>what is it saying?: not sure what this book is...</td>\n    </tr>\n    <tr>\n      <th>3599999</th>\n      <td>2</td>\n      <td>Makes My Blood Run Red-White-And-Blue: I agree...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3600000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"df = train.copy()\ndf2 = test.copy()","metadata":{"execution":{"iopub.status.busy":"2025-04-19T06:29:43.869078Z","iopub.execute_input":"2025-04-19T06:29:43.869311Z","iopub.status.idle":"2025-04-19T06:29:43.978855Z","shell.execute_reply.started":"2025-04-19T06:29:43.869291Z","shell.execute_reply":"2025-04-19T06:29:43.978190Z"},"trusted":true},"outputs":[],"execution_count":7},{"cell_type":"code","source":"df.label = df.label.map({2:0, 1:1})  # 1 are negatives (targeted class)\ndf2.label = df2.label.map({2:0, 1:1})  # 1 are negatives (targeted class)\n\ndf","metadata":{"execution":{"iopub.status.busy":"2025-04-19T06:29:43.979652Z","iopub.execute_input":"2025-04-19T06:29:43.979879Z","iopub.status.idle":"2025-04-19T06:29:44.043573Z","shell.execute_reply.started":"2025-04-19T06:29:43.979860Z","shell.execute_reply":"2025-04-19T06:29:44.042704Z"},"trusted":true},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"         label                                               text\n0            0  Stuning even for the non-gamer: This sound tra...\n1            0  The best soundtrack ever to anything.: I'm rea...\n2            0  Amazing!: This soundtrack is my favorite music...\n3            0  Excellent Soundtrack: I truly like this soundt...\n4            0  Remember, Pull Your Jaw Off The Floor After He...\n...        ...                                                ...\n3599995      1  Don't do it!!: The high chair looks great when...\n3599996      1  Looks nice, low functionality: I have used thi...\n3599997      1  compact, but hard to clean: We have a small ho...\n3599998      1  what is it saying?: not sure what this book is...\n3599999      0  Makes My Blood Run Red-White-And-Blue: I agree...\n\n[3600000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Stuning even for the non-gamer: This sound tra...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>The best soundtrack ever to anything.: I'm rea...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Amazing!: This soundtrack is my favorite music...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>Excellent Soundtrack: I truly like this soundt...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3599995</th>\n      <td>1</td>\n      <td>Don't do it!!: The high chair looks great when...</td>\n    </tr>\n    <tr>\n      <th>3599996</th>\n      <td>1</td>\n      <td>Looks nice, low functionality: I have used thi...</td>\n    </tr>\n    <tr>\n      <th>3599997</th>\n      <td>1</td>\n      <td>compact, but hard to clean: We have a small ho...</td>\n    </tr>\n    <tr>\n      <th>3599998</th>\n      <td>1</td>\n      <td>what is it saying?: not sure what this book is...</td>\n    </tr>\n    <tr>\n      <th>3599999</th>\n      <td>0</td>\n      <td>Makes My Blood Run Red-White-And-Blue: I agree...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3600000 rows × 2 columns</p>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"df.label.value_counts(normalize=True)\ndf2.label.value_counts(normalize=True)\n","metadata":{"execution":{"iopub.status.busy":"2025-04-19T06:29:44.044366Z","iopub.execute_input":"2025-04-19T06:29:44.044607Z","iopub.status.idle":"2025-04-19T06:29:44.076321Z","shell.execute_reply.started":"2025-04-19T06:29:44.044588Z","shell.execute_reply":"2025-04-19T06:29:44.075677Z"},"trusted":true},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"label\n0    0.5\n1    0.5\nName: proportion, dtype: float64"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"df = pd.concat([df, df2], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:29:44.077158Z","iopub.execute_input":"2025-04-19T06:29:44.077459Z","iopub.status.idle":"2025-04-19T06:29:44.208611Z","shell.execute_reply.started":"2025-04-19T06:29:44.077430Z","shell.execute_reply":"2025-04-19T06:29:44.207283Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"df.info","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:29:44.211698Z","iopub.execute_input":"2025-04-19T06:29:44.211909Z","iopub.status.idle":"2025-04-19T06:29:44.219789Z","shell.execute_reply.started":"2025-04-19T06:29:44.211892Z","shell.execute_reply":"2025-04-19T06:29:44.218760Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"<bound method DataFrame.info of          label                                               text\n0            0  Stuning even for the non-gamer: This sound tra...\n1            0  The best soundtrack ever to anything.: I'm rea...\n2            0  Amazing!: This soundtrack is my favorite music...\n3            0  Excellent Soundtrack: I truly like this soundt...\n4            0  Remember, Pull Your Jaw Off The Floor After He...\n...        ...                                                ...\n3999995      1  Unbelievable- In a Bad Way: We bought this Tho...\n3999996      1  Almost Great, Until it Broke...: My son reciev...\n3999997      1  Disappointed !!!: I bought this toy for my son...\n3999998      0  Classic Jessica Mitford: This is a compilation...\n3999999      1  Comedy Scene, and Not Heard: This DVD will be ...\n\n[4000000 rows x 2 columns]>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"df.to_csv('amazon_reviews.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2025-04-19T06:29:44.221974Z","iopub.execute_input":"2025-04-19T06:29:44.222238Z","iopub.status.idle":"2025-04-19T06:30:18.218400Z","shell.execute_reply.started":"2025-04-19T06:29:44.222210Z","shell.execute_reply":"2025-04-19T06:30:18.217469Z"},"trusted":true},"outputs":[],"execution_count":12},{"cell_type":"code","source":"df.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:30:18.219566Z","iopub.execute_input":"2025-04-19T06:30:18.219815Z","iopub.status.idle":"2025-04-19T06:30:18.227209Z","shell.execute_reply.started":"2025-04-19T06:30:18.219793Z","shell.execute_reply":"2025-04-19T06:30:18.226562Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"   label                                               text\n0      0  Stuning even for the non-gamer: This sound tra...\n1      0  The best soundtrack ever to anything.: I'm rea...\n2      0  Amazing!: This soundtrack is my favorite music...\n3      0  Excellent Soundtrack: I truly like this soundt...\n4      0  Remember, Pull Your Jaw Off The Floor After He...","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>Stuning even for the non-gamer: This sound tra...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>The best soundtrack ever to anything.: I'm rea...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>Amazing!: This soundtrack is my favorite music...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>Excellent Soundtrack: I truly like this soundt...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"code","source":"import re\n\ndef preprocess_text(text):\n    text = text.lower()  # Convert to lowercase\n    text = re.sub(r'\\d+', '', text)  # Remove numbers\n    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n    return text\n\n# Apply preprocessing\ndf['text'] = df['text'].apply(preprocess_text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:30:18.227964Z","iopub.execute_input":"2025-04-19T06:30:18.228245Z","iopub.status.idle":"2025-04-19T06:31:31.068229Z","shell.execute_reply.started":"2025-04-19T06:30:18.228217Z","shell.execute_reply":"2025-04-19T06:31:31.067585Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\n# Define the feature (X) and target (y) columns\nX = df['text']\ny = df['label']\n\n\n# Split data into training and test sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Vectorize the text data\nvectorizer = TfidfVectorizer(max_features=5000)\nX_train_vectorized = vectorizer.fit_transform(X_train)\nX_test_vectorized = vectorizer.transform(X_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:31:31.068960Z","iopub.execute_input":"2025-04-19T06:31:31.069211Z","iopub.status.idle":"2025-04-19T06:35:18.190690Z","shell.execute_reply.started":"2025-04-19T06:31:31.069191Z","shell.execute_reply":"2025-04-19T06:35:18.189946Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"# Train Naive Bayes model\nnb_model = MultinomialNB()\nnb_model.fit(X_train_vectorized, y_train)\n\n# Train Naive Bayes model\n#rf_model = RandomForestClassifier(n_estimators=100)\n#rf_model.fit(X_train_vectorized, y_train)\n\n# Train Naive Bayes model\nlg_model = LogisticRegression()\nlg_model.fit(X_train_vectorized, y_train)\n\n# Make predictions and evaluate the model\n#y_pred = rf_model.predict(X_test_vectorized)\n#print(\"Random Forest Model Performance\")\n#print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n#print(classification_report(y_test, y_pred))\n\n# Make predictions and evaluate the model\ny_pred = nb_model.predict(X_test_vectorized)\nprint(\"Naive Bayes Model Performance\")\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))\n\n# Make predictions and evaluate the model\ny_pred = lg_model.predict(X_test_vectorized)\nprint(\"Logistic Regression Model Performance\")\nprint(\"Accuracy:\", accuracy_score(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:35:18.191406Z","iopub.execute_input":"2025-04-19T06:35:18.191751Z","iopub.status.idle":"2025-04-19T06:36:28.209569Z","shell.execute_reply.started":"2025-04-19T06:35:18.191729Z","shell.execute_reply":"2025-04-19T06:36:28.208551Z"}},"outputs":[{"name":"stdout","text":"Naive Bayes Model Performance\nAccuracy: 0.8481\n              precision    recall  f1-score   support\n\n           0       0.85      0.84      0.85    399907\n           1       0.84      0.85      0.85    400093\n\n    accuracy                           0.85    800000\n   macro avg       0.85      0.85      0.85    800000\nweighted avg       0.85      0.85      0.85    800000\n\nLogistic Regression Model Performance\nAccuracy: 0.900755\n              precision    recall  f1-score   support\n\n           0       0.90      0.90      0.90    399907\n           1       0.90      0.90      0.90    400093\n\n    accuracy                           0.90    800000\n   macro avg       0.90      0.90      0.90    800000\nweighted avg       0.90      0.90      0.90    800000\n\n","output_type":"stream"}],"execution_count":16},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Tokenize text data\ntokenizer = Tokenizer(num_words=5000)\ntokenizer.fit_on_texts(X_train)\nX_train_sequences = tokenizer.texts_to_sequences(X_train)\nX_test_sequences = tokenizer.texts_to_sequences(X_test)\n\n# Pad sequences\nmax_sequence_length = max(len(seq) for seq in X_train_sequences)\nX_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\nX_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:36:28.210597Z","iopub.execute_input":"2025-04-19T06:36:28.210855Z","iopub.status.idle":"2025-04-19T06:42:33.636412Z","shell.execute_reply.started":"2025-04-19T06:36:28.210824Z","shell.execute_reply":"2025-04-19T06:42:33.635701Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Embedding, LSTM, Dense\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.callbacks import EarlyStopping\n\n# LSTM modelini oluşturma\nmodel = Sequential()\nmodel.add(Embedding(input_dim=5000, output_dim=128, input_length=max_sequence_length))\nmodel.add(LSTM(64))\nmodel.add(Dense(1, activation='sigmoid'))\n\n# Modeli derleme\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Early stopping tanımlama\nearly_stopping = EarlyStopping(\n    monitor='val_loss',  # İzlenecek metrik\n    patience=3,          # Doğrulama kaybı iyileşmediğinde kaç epoch bekleyeceği\n    restore_best_weights=True  # En iyi ağırlıkları geri yükle\n)\n\n# Modeli eğitme\nhistory = model.fit(\n    X_train_padded, y_train,\n    epochs=3,  # Eğitim süresini uzatabiliriz çünkü early stopping ile erken durdurma yapılacak\n    batch_size=32,\n    validation_split=0.1,\n    callbacks=[early_stopping]  # Early stopping'i geri çağırmalara ekleyin\n)\n\n# Modeli değerlendirme\nloss, accuracy = model.evaluate(X_test_padded, y_test)\nprint(\"LSTM Model Performansı\")\nprint(\"Accuracy:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T06:42:33.637248Z","iopub.execute_input":"2025-04-19T06:42:33.637917Z","iopub.status.idle":"2025-04-19T07:25:51.359599Z","shell.execute_reply.started":"2025-04-19T06:42:33.637885Z","shell.execute_reply":"2025-04-19T07:25:51.358647Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n\u001b[1m90000/90000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m830s\u001b[0m 9ms/step - accuracy: 0.9213 - loss: 0.1993 - val_accuracy: 0.9431 - val_loss: 0.1501\nEpoch 2/3\n\u001b[1m90000/90000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m828s\u001b[0m 9ms/step - accuracy: 0.9480 - loss: 0.1392 - val_accuracy: 0.9475 - val_loss: 0.1408\nEpoch 3/3\n\u001b[1m90000/90000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m829s\u001b[0m 9ms/step - accuracy: 0.9521 - loss: 0.1293 - val_accuracy: 0.9481 - val_loss: 0.1390\n\u001b[1m25000/25000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 4ms/step - accuracy: 0.9480 - loss: 0.1392\nLSTM Model Performansı\nAccuracy: 0.9478762745857239\n","output_type":"stream"}],"execution_count":18},{"cell_type":"code","source":"\"\"\"from sklearn.metrics import accuracy_score, f1_score\n\n# Tahminler (0 veya 1)\ny_pred = (model.predict(X_test_padded) > 0.5).astype(\"int32\")\n\n# Skorlar\nacc = accuracy_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\n\nprint(f\"Accuracy: {acc:.4f}\")\nprint(f\"F1 Score: {f1:.4f}\")\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T07:25:51.360610Z","iopub.execute_input":"2025-04-19T07:25:51.360917Z","iopub.status.idle":"2025-04-19T07:25:51.366435Z","shell.execute_reply.started":"2025-04-19T07:25:51.360883Z","shell.execute_reply":"2025-04-19T07:25:51.365702Z"}},"outputs":[{"execution_count":19,"output_type":"execute_result","data":{"text/plain":"'from sklearn.metrics import accuracy_score, f1_score\\n\\n# Tahminler (0 veya 1)\\ny_pred = (model.predict(X_test_padded) > 0.5).astype(\"int32\")\\n\\n# Skorlar\\nacc = accuracy_score(y_test, y_pred)\\nf1 = f1_score(y_test, y_pred)\\n\\nprint(f\"Accuracy: {acc:.4f}\")\\nprint(f\"F1 Score: {f1:.4f}\")'"},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n\n# Tahminler (0 veya 1)\ny_pred = (model.predict(X_test_padded) > 0.5).astype(\"int32\")\n\n# Skorlar\nacc = accuracy_score(y_test, y_pred)\nf1 = f1_score(y_test, y_pred)\nprecision = precision_score(y_test, y_pred)\nrecall = recall_score(y_test, y_pred)\n\nprint(f\"Accuracy : {acc:.4f}\")\nprint(f\"F1 Score : {f1:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall   : {recall:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T07:25:51.367154Z","iopub.execute_input":"2025-04-19T07:25:51.367456Z","iopub.status.idle":"2025-04-19T07:27:44.396776Z","shell.execute_reply.started":"2025-04-19T07:25:51.367424Z","shell.execute_reply":"2025-04-19T07:27:44.395837Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m25000/25000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 4ms/step\nAccuracy : 0.9479\nF1 Score : 0.9480\nPrecision: 0.9461\nRecall   : 0.9499\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"# Save the entire model\nmodel.save(\"lstm_model.h5\")  # You can also use .keras extension (e.g., \"lstm_model.keras\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T07:27:44.397729Z","iopub.execute_input":"2025-04-19T07:27:44.398012Z","iopub.status.idle":"2025-04-19T07:27:44.451332Z","shell.execute_reply.started":"2025-04-19T07:27:44.397976Z","shell.execute_reply":"2025-04-19T07:27:44.450705Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Embedding, Conv1D, GlobalMaxPooling1D, Dense\nfrom keras.callbacks import EarlyStopping\n\ncnn_model = Sequential()\ncnn_model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_sequence_length))\ncnn_model.add(Conv1D(filters=128, kernel_size=5, activation='relu'))\ncnn_model.add(GlobalMaxPooling1D())\ncnn_model.add(Dense(1, activation='sigmoid'))\n\ncnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\ncnn_history = cnn_model.fit(\n    X_train_padded, y_train,\n    epochs=5,\n    batch_size=32,\n    validation_split=0.1,\n    callbacks=[early_stopping]\n)\n\nloss, accuracy = cnn_model.evaluate(X_test_padded, y_test)\nprint(\"📊 CNN Model Performansı\")\nprint(\"Accuracy:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T07:27:44.452121Z","iopub.execute_input":"2025-04-19T07:27:44.452450Z","iopub.status.idle":"2025-04-19T07:48:28.834935Z","shell.execute_reply.started":"2025-04-19T07:27:44.452416Z","shell.execute_reply":"2025-04-19T07:48:28.834138Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n\u001b[1m90000/90000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m244s\u001b[0m 3ms/step - accuracy: 0.9235 - loss: 0.1941 - val_accuracy: 0.9420 - val_loss: 0.1545\nEpoch 2/5\n\u001b[1m90000/90000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 3ms/step - accuracy: 0.9437 - loss: 0.1502 - val_accuracy: 0.9425 - val_loss: 0.1526\nEpoch 3/5\n\u001b[1m90000/90000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 3ms/step - accuracy: 0.9499 - loss: 0.1360 - val_accuracy: 0.9410 - val_loss: 0.1577\nEpoch 4/5\n\u001b[1m90000/90000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m239s\u001b[0m 3ms/step - accuracy: 0.9542 - loss: 0.1258 - val_accuracy: 0.9427 - val_loss: 0.1554\nEpoch 5/5\n\u001b[1m90000/90000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m238s\u001b[0m 3ms/step - accuracy: 0.9582 - loss: 0.1167 - val_accuracy: 0.9408 - val_loss: 0.1637\n\u001b[1m25000/25000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 2ms/step - accuracy: 0.9421 - loss: 0.1529\n📊 CNN Model Performansı\nAccuracy: 0.9420074820518494\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\n\n# Tahminler (0 veya 1)\ny_pred = (cnn_model.predict(X_test_padded) > 0.5).astype(\"int32\")\n\n# Skorlar\ncnn_acc = accuracy_score(y_test, y_pred)\ncnn_f1 = f1_score(y_test, y_pred)\ncnn_precision = precision_score(y_test, y_pred)\ncnn_recall = recall_score(y_test, y_pred)\n\nprint(f\"Accuracy : {cnn_acc:.4f}\")\nprint(f\"F1 Score : {cnn_f1:.4f}\")\nprint(f\"Precision: {cnn_precision:.4f}\")\nprint(f\"Recall   : {cnn_recall:.4f}\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T07:48:28.835776Z","iopub.execute_input":"2025-04-19T07:48:28.836014Z","iopub.status.idle":"2025-04-19T07:49:11.836853Z","shell.execute_reply.started":"2025-04-19T07:48:28.835994Z","shell.execute_reply":"2025-04-19T07:49:11.836092Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m25000/25000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 1ms/step\nAccuracy : 0.9420\nF1 Score : 0.9414\nPrecision: 0.9515\nRecall   : 0.9315\n","output_type":"stream"}],"execution_count":23},{"cell_type":"code","source":"cnn_model.save(\"cnn_model.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T07:49:11.837697Z","iopub.execute_input":"2025-04-19T07:49:11.838008Z","iopub.status.idle":"2025-04-19T07:49:11.872296Z","shell.execute_reply.started":"2025-04-19T07:49:11.837977Z","shell.execute_reply":"2025-04-19T07:49:11.871685Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Embedding, GRU, Dense\n\ngru_model = Sequential()\ngru_model.add(Embedding(input_dim=5000, output_dim=128, input_length=max_sequence_length))\ngru_model.add(GRU(64))\ngru_model.add(Dense(1, activation='sigmoid'))\n\ngru_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\nearly_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n\ngru_history = gru_model.fit(\n    X_train_padded, y_train,\n    epochs=3,\n    batch_size=32,\n    validation_split=0.1,\n    callbacks=[early_stopping]\n)\n\nloss, accuracy = gru_model.evaluate(X_test_padded, y_test)\nprint(\"📊 GRU Model Performansı\")\nprint(\"Accuracy:\", accuracy)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T07:49:11.873107Z","iopub.execute_input":"2025-04-19T07:49:11.873305Z","iopub.status.idle":"2025-04-19T08:30:53.389834Z","shell.execute_reply.started":"2025-04-19T07:49:11.873288Z","shell.execute_reply":"2025-04-19T08:30:53.388878Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/3\n\u001b[1m90000/90000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m797s\u001b[0m 9ms/step - accuracy: 0.9243 - loss: 0.1893 - val_accuracy: 0.9457 - val_loss: 0.1440\nEpoch 2/3\n\u001b[1m90000/90000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m800s\u001b[0m 9ms/step - accuracy: 0.9481 - loss: 0.1383 - val_accuracy: 0.9466 - val_loss: 0.1415\nEpoch 3/3\n\u001b[1m90000/90000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m796s\u001b[0m 9ms/step - accuracy: 0.9505 - loss: 0.1327 - val_accuracy: 0.9460 - val_loss: 0.1431\n\u001b[1m25000/25000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 4ms/step - accuracy: 0.9462 - loss: 0.1420\n📊 GRU Model Performansı\nAccuracy: 0.9458462595939636\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, f1_score\n\n# Tahminler (0 veya 1)\ny_pred = (gru_model.predict(X_test_padded) > 0.5).astype(\"int32\")\n\n# Skorlar\ngru_acc = accuracy_score(y_test, y_pred)\ngru_f1 = f1_score(y_test, y_pred)\ngru_precision = precision_score(y_test, y_pred)\ngru_recall = recall_score(y_test, y_pred)\n\nprint(f\"Accuracy : {gru_acc:.4f}\")\nprint(f\"F1 Score : {gru_f1:.4f}\")\nprint(f\"Precision: {gru_precision:.4f}\")\nprint(f\"Recall   : {gru_recall:.4f}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T08:30:53.393021Z","iopub.execute_input":"2025-04-19T08:30:53.393241Z","iopub.status.idle":"2025-04-19T08:32:39.650466Z","shell.execute_reply.started":"2025-04-19T08:30:53.393223Z","shell.execute_reply":"2025-04-19T08:32:39.649335Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m25000/25000\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m95s\u001b[0m 4ms/step\nAccuracy : 0.9458\nF1 Score : 0.9458\nPrecision: 0.9468\nRecall   : 0.9448\n","output_type":"stream"}],"execution_count":26},{"cell_type":"code","source":"gru_model.save(\"gru_model.h5\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T08:32:39.651870Z","iopub.execute_input":"2025-04-19T08:32:39.652206Z","iopub.status.idle":"2025-04-19T08:32:39.696811Z","shell.execute_reply.started":"2025-04-19T08:32:39.652172Z","shell.execute_reply":"2025-04-19T08:32:39.695748Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Embedding, LSTM, Conv1D, GlobalMaxPooling1D, Dense, Dropout, Concatenate, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom transformers import TFAutoModel, AutoTokenizer\nfrom sklearn.metrics import classification_report\nfrom sklearn.model_selection import train_test_split\n\n# Load dataset\ndata = pd.read_csv('amazon_reviews.csv')\nX = data['text'].astype(str)\ny = data['label']\n\n# Split dataset\nX_train_texts, X_test_texts, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Tokenization and padding (for CNN & LSTM views)\ntokenizer = Tokenizer(num_words=5000)\ntokenizer.fit_on_texts(X_train_texts)\nX_train_sequences = tokenizer.texts_to_sequences(X_train_texts)\nX_test_sequences = tokenizer.texts_to_sequences(X_test_texts)\n\nmax_sequence_length = max(max(len(seq) for seq in X_train_sequences), 100)  # safety max\n\nX_train_padded = pad_sequences(X_train_sequences, maxlen=max_sequence_length)\nX_test_padded = pad_sequences(X_test_sequences, maxlen=max_sequence_length)\n\n# Transformer tokenization\ntransformer_model_name = \"bert-base-uncased\"\ntransformer_tokenizer = AutoTokenizer.from_pretrained(transformer_model_name)\ntransformer_model = TFAutoModel.from_pretrained(transformer_model_name)\n\ndef encode_transformer(texts, tokenizer, max_len):\n    encoding = tokenizer(\n        list(texts),\n        padding='max_length',\n        truncation=True,\n        max_length=max_len,\n        return_tensors='tf'\n    )\n    return encoding['input_ids']\n\nX_train_transformer = encode_transformer(X_train_texts, transformer_tokenizer, max_sequence_length)\nX_test_transformer = encode_transformer(X_test_texts, transformer_tokenizer, max_sequence_length)\n\n# Define Inputs\ncnn_input = Input(shape=(max_sequence_length,))\nlstm_input = Input(shape=(max_sequence_length,))\ntransformer_input = Input(shape=(max_sequence_length,), dtype=tf.int32)\n\n# CNN View\ncnn_embedding = Embedding(input_dim=5000, output_dim=128, input_length=max_sequence_length)(cnn_input)\ncnn_conv = Conv1D(filters=128, kernel_size=5, activation='relu')(cnn_embedding)\ncnn_pool = GlobalMaxPooling1D()(cnn_conv)\n\n# LSTM View\nlstm_embedding = Embedding(input_dim=5000, output_dim=128, input_length=max_sequence_length)(lstm_input)\nlstm_layer = LSTM(64)(lstm_embedding)\n\n# Transformer View\ntransformer_embedding = transformer_model(transformer_input)[0]\ntransformer_pool = GlobalMaxPooling1D()(transformer_embedding)\n\n# Merge all views\nmerged = Concatenate()([cnn_pool, lstm_layer, transformer_pool])\nmerged = Dropout(0.5)(merged)\noutput = Dense(1, activation='sigmoid')(merged)\n\n# Define and compile model\nmodel = Model(inputs=[cnn_input, lstm_input, transformer_input], outputs=output)\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nmodel.summary()\n\n# Train the model\nhistory = model.fit(\n    [X_train_padded, X_train_padded, X_train_transformer],\n    y_train,\n    validation_split=0.1,\n    epochs=3,\n    batch_size=32\n)\n\n# Evaluate on test data\ny_pred_probs = model.predict([X_test_padded, X_test_padded, X_test_transformer])\ny_pred = (y_pred_probs > 0.5).astype(int)\n\n# Print metrics\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_test, y_pred, digits=4))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-19T08:39:16.565192Z","iopub.execute_input":"2025-04-19T08:39:16.565548Z","execution_failed":"2025-04-19T09:15:24.885Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"db4ac034eaa04a0ab417076c1bcccdd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8400310af9794910b131b9b462ae4504"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e2d179bbbde47519dc689b94e251bd6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"195a00e6ded4417cb197b77736d9ee86"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5573db0af8f74a9caa5e418c8833d886"}},"metadata":{}},{"name":"stderr","text":"Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\nAll the weights of TFBertModel were initialized from the PyTorch model.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}